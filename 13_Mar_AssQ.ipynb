{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means among three or more groups. It assumes that:\n",
    "\n",
    "Independence: The observations are independent of each other, and there is no relationship between the observations in different groups.\n",
    "\n",
    "Normality: The data for each group are normally distributed.\n",
    "\n",
    "Homogeneity of variance: The variance of the data in each group is approximately equal.\n",
    "\n",
    "Random sampling: The sample data should be selected randomly from the population.\n",
    "\n",
    "Violations of these assumptions can impact the validity of the ANOVA results. Here are some examples of potential violations:\n",
    "\n",
    "Violation of independence: If the observations within groups are not independent, the ANOVA results may be biased. For example, if the same individuals are measured in multiple groups, then the observations may not be independent.\n",
    "\n",
    "Violation of normality: If the data are not normally distributed, the ANOVA results may be inaccurate. For example, if the data are heavily skewed or contain outliers, then the normality assumption may not hold.\n",
    "\n",
    "Violation of homogeneity of variance: If the variance of the data is not approximately equal across all groups, the ANOVA results may be incorrect. For example, if the variance in one group is much larger than the variance in another group, the ANOVA may incorrectly identify a significant difference between the groups.\n",
    "\n",
    "Violation of random sampling: If the sample is not selected randomly, the ANOVA results may not be representative of the population. For example, if a convenience sample is used instead of a random sample, the ANOVA may not accurately reflect the population means.\n",
    "\n",
    "It is important to check the assumptions before conducting ANOVA to ensure the validity of the results. If assumptions are violated, alternative statistical methods or data transformation techniques can be used."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The three types of ANOVA are:\n",
    "\n",
    ">One-way ANOVA: This is used when comparing the means of three or more groups that are independent of each other on a single factor or independent variable. For example, comparing the mean heights of individuals from three different countries.\n",
    "\n",
    ">Two-way ANOVA: This is used when comparing the means of two or more groups that are independent of each other on two factors or independent variables. For example, comparing the mean scores of students who received different teaching methods in two different schools.\n",
    "\n",
    ">MANOVA (Multivariate Analysis of Variance): This is used when there are multiple dependent variables and the goal is to determine if there is a significant difference between the means of three or more groups. For example, comparing the mean scores of students in different subjects.\n",
    "\n",
    ">In general, one-way ANOVA is used when there is only one independent variable, two-way ANOVA is used when there are two independent variables, and MANOVA is used when there are multiple dependent variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The partitioning of variance in ANOVA refers to the decomposition of the total variability of the data into different components that can be attributed to different sources of variation. The total variability in the data is divided into two components: variation between groups and variation within groups. The variation between groups is due to differences among the means of the different groups being compared, while the variation within groups is due to the variability of the individual observations within each group.\n",
    "\n",
    ">Partitioning of variance is important in ANOVA because it allows us to quantify the relative importance of the different sources of variation in the data. By calculating the proportion of the total variability that is attributable to the between-group variation, we can determine whether there is a statistically significant difference between the groups being compared. In addition, the partitioning of variance allows us to calculate effect sizes, which can help us to interpret the practical significance of the observed differences between groups.\n",
    "\n",
    ">Understanding the partitioning of variance is also important in the design of experiments, as it can help researchers to determine the optimal sample size and statistical power for their study. By estimating the expected variance between groups and within groups, researchers can calculate the minimum sample size required to detect a given effect size with a given level of statistical power."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">In a one-way ANOVA using Python, we can use the f_oneway() function from the scipy.stats module to calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR).\n",
    "\n",
    ">Here is an example code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sum of squares (SST): 70.0\n",
      "Explained sum of squares (SSE): 40.0\n",
      "Residual sum of squares (SSR): 30.0\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# create some sample data for three groups\n",
    "group1 = [1, 2, 3, 4, 5]\n",
    "group2 = [3, 4, 5, 6, 7]\n",
    "group3 = [5, 6, 7, 8, 9]\n",
    "\n",
    "# calculate the ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "# calculate the total sum of squares (SST)\n",
    "mean_all = sum(group1 + group2 + group3) / 15\n",
    "SST = sum((x - mean_all) ** 2 for x in group1 + group2 + group3)\n",
    "\n",
    "# calculate the explained sum of squares (SSE)\n",
    "mean_group1 = sum(group1) / 5\n",
    "mean_group2 = sum(group2) / 5\n",
    "mean_group3 = sum(group3) / 5\n",
    "SSE = 5 * ((mean_group1 - mean_all) ** 2 + (mean_group2 - mean_all) ** 2 + (mean_group3 - mean_all) ** 2)\n",
    "\n",
    "# calculate the residual sum of squares (SSR)\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total sum of squares (SST):\", SST)\n",
    "print(\"Explained sum of squares (SSE):\", SSE)\n",
    "print(\"Residual sum of squares (SSR):\", SSR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Note that SST represents the total variability in the data, SSE represents the variability explained by the group means, and SSR represents the variability not explained by the group means. It is important to understand these concepts because they help us to interpret the ANOVA results and determine if there is a significant difference between the groups."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a two-way ANOVA, the main effects are calculated by comparing the means of each factor while holding the other factor constant. The interaction effect is calculated by determining whether the effect of one factor on the response variable changes at different levels of the other factor.\n",
    "\n",
    "To calculate the main effects and interaction effect using Python, you can use the statsmodels library. Here's an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame with the data\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 1, 2, 2], 'B': [1, 2, 1, 2], 'DV': [5, 6, 7, 8]})\n",
    "\n",
    "# Calculate the mean of DV for each level of A\n",
    "means_a = df.groupby('A')['DV'].mean()\n",
    "\n",
    "# Calculate the main effect of A as the difference between means\n",
    "main_effect_a = means_a[2] - means_a[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of DV for each level of B\n",
    "means_b = df.groupby('B')['DV'].mean()\n",
    "\n",
    "# Calculate the main effect of B as the difference between means\n",
    "main_effect_b = means_b[2] - means_b[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of DV for each combination of A and B levels\n",
    "means_ab = df.groupby(['A', 'B'])['DV'].mean()\n",
    "\n",
    "# Calculate the interaction effect as the difference between means for each level of A, holding B constant\n",
    "interaction_effect_a = (means_ab[2, 2] - means_ab[2, 1]) - (means_ab[1, 2] - means_ab[1, 1])\n",
    "\n",
    "# Calculate the interaction effect as the difference between means for each level of B, holding A constant\n",
    "interaction_effect_b = (means_ab[2, 2] - means_ab[1, 2]) - (means_ab[2, 1] - means_ab[1, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An F-statistic of 5.23 and a p-value of 0.02 suggests that there are significant differences between the groups in terms of the outcome variable. The null hypothesis (i.e., that there are no differences between the groups) is rejected in favor of the alternative hypothesis (i.e., that at least one group is different from the others).\n",
    "\n",
    "The magnitude of the F-statistic (i.e., 5.23) indicates the degree of variability between the groups relative to the variability within the groups. A larger F-statistic suggests that the variability between the groups is greater than the variability within the groups, which strengthens the evidence for the alternative hypothesis.\n",
    "\n",
    "In summary, the results suggest that there are significant differences between the groups in terms of the outcome variable, and it is likely that at least one group differs significantly from the others."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can occur when some participants do not complete all the measurements or when some measurements are lost due to technical issues. One common approach to handle missing data is to remove any participants who have missing data, which is known as complete case analysis. Another approach is to impute the missing data using methods such as mean imputation, last observation carried forward, or multiple imputation.\n",
    "\n",
    "However, it is important to note that different methods of handling missing data can lead to different results and conclusions. Complete case analysis can lead to biased estimates if the missing data is not missing completely at random, meaning that the probability of missing data depends on unobserved variables. Imputation methods can also introduce bias if the imputed values do not accurately represent the missing data. In general, it is recommended to report the results of different methods of handling missing data and to conduct sensitivity analyses to assess the robustness of the findings."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after ANOVA to determine which specific groups are significantly different from each other. Some common post-hoc tests include Tukey's HSD (Honestly Significant Difference), Bonferroni correction, and Dunnett's test.\n",
    "\n",
    "Tukey's HSD is used to compare all possible pairs of means in a one-way ANOVA. Bonferroni correction is used to adjust the p-values of multiple comparisons to control for Type I errors. Dunnett's test is used to compare each group to a control group.\n",
    "\n",
    "An example of a situation where a post-hoc test might be necessary is in a study comparing the effectiveness of three different treatments for a medical condition. If the ANOVA test shows a significant difference between the three treatments, a post-hoc test can be used to determine which specific treatments are significantly different from each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 41.27483930475887\n",
      "p-value: 1.141610739614359e-12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# create a dataframe with the weight loss data\n",
    "data = {'Diet A': [3.2, 4.1, 2.8, 5.5, 3.7, 2.6, 4.2, 2.9, 4.8, 3.5,\n",
    "                   2.4, 4.0, 3.6, 4.4, 5.1, 3.3, 4.5, 2.7, 3.9, 4.3,\n",
    "                   3.1, 4.6, 3.8, 2.5, 4.9],\n",
    "        'Diet B': [2.5, 3.4, 1.8, 2.7, 3.1, 2.9, 3.3, 3.8, 2.3, 3.0,\n",
    "                   2.6, 2.1, 3.2, 2.8, 2.7, 2.5, 3.1, 3.5, 2.9, 2.2,\n",
    "                   2.4, 2.6, 3.7, 3.3, 2.8],\n",
    "        'Diet C': [1.8, 2.3, 1.5, 2.1, 2.5, 2.7, 2.8, 2.2, 2.9, 1.9,\n",
    "                   2.4, 2.0, 1.7, 2.6, 2.3, 1.5, 1.9, 2.1, 1.8, 2.2,\n",
    "                   2.3, 2.7, 2.1, 2.4, 2.0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# conduct one-way ANOVA\n",
    "f_stat, p_val = stats.f_oneway(df['Diet A'], df['Diet B'], df['Diet C'])\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_val)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            sum_sq   df          F    PR(>F)\n",
      "C(Program)                0.700833  1.0   3.298039  0.211012\n",
      "C(Experience)             0.240833  1.0   1.133333  0.398583\n",
      "C(Program):C(Experience)  2.900833  1.0  13.650980  0.066077\n",
      "Residual                  0.425000  2.0        NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# create a DataFrame with the data\n",
    "data = {'Program': ['A', 'A', 'A', 'C', 'C', 'C'],\n",
    "        'Experience': ['Novice', 'Experienced', 'Novice', 'Experienced', 'Novice', 'Experienced'],\n",
    "        'Time': [10.5, 9.8, 11.2, 12.3, 10.1, 11.7]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# fit the two-way ANOVA model\n",
    "model = ols('Time ~ C(Program) + C(Experience) + C(Program):C(Experience)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct a two-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To conduct a two-sample t-test in Python, we can use the ttest_ind function from the scipy.stats module. Here's how we can do it for the given scenario:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -3.6385791607023052\n",
      "p-value: 0.0004398574819606739\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "# generate some sample data\n",
    "np.random.seed(1)\n",
    "control_scores = np.random.normal(70, 10, 50)\n",
    "experimental_scores = np.random.normal(75, 12, 50)\n",
    "\n",
    "# conduct two-sample t-test\n",
    "t_stat, p_value = ttest_ind(control_scores, experimental_scores, equal_var=False)\n",
    "\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The null hypothesis in a two-sample t-test is that the means of the two groups are equal. The p-value of 0.0236 is less than the significance level of 0.05, so we can reject the null hypothesis and conclude that there is a significant difference in test scores between the control and experimental groups.\n",
    "\n",
    "To follow up with a post-hoc test, we can use the Tukey HSD test, which can be performed using the pairwise_tukeyhsd function from the statsmodels.stats.multicomp module. Here's how we can do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05    \n",
      "==========================================================\n",
      " group1    group2    meandiff p-adj  lower   upper  reject\n",
      "----------------------------------------------------------\n",
      "control experimental   7.0153 0.0004 3.1892 10.8414   True\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# create data frame for the scores\n",
    "import pandas as pd\n",
    "scores_df = pd.DataFrame({\"score\": np.concatenate([control_scores, experimental_scores]),\n",
    "                          \"group\": [\"control\"] * 50 + [\"experimental\"] * 50})\n",
    "\n",
    "# perform Tukey HSD test\n",
    "tukey_results = pairwise_tukeyhsd(scores_df[\"score\"], scores_df[\"group\"])\n",
    "\n",
    "print(tukey_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Tukey HSD test compares all possible pairs of groups and determines if there are any significant differences. In this case, there is only one comparison to be made, between the control and experimental groups. The results indicate that there is a significant difference in means between the two groups, with the experimental group having a higher mean score than the control group."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the same stores are measured on 30 different days, we can use a repeated measures ANOVA to test for differences between the three stores.\n",
    "\n",
    "First, we can load the necessary libraries and create a DataFrame with the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "sales_data = pd.DataFrame({'Store': ['A', 'A', 'A', 'C', 'C', 'C'],\n",
    "                           'Day': [1, 2, 3, 28, 29, 30],\n",
    "                           'Sales': [100, 110, 120, 80, 90, 100]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          sum_sq   df    F    PR(>F)\n",
      "C(Store)   600.0  1.0  6.0  0.070484\n",
      "Residual   400.0  4.0  NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Next, we can create a repeated measures ANOVA model and fit it to the data:\n",
    "\n",
    "rm = ols('Sales ~ C(Store)', data=sales_data).fit()\n",
    "anova_table = sm.stats.anova_lm(rm, typ=2)\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output an ANOVA table with the results of the analysis. We can then follow up with post-hoc tests to determine which stores differ significantly from each other. One way to do this is to use Tukey's HSD (honest significant difference) test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "====================================================\n",
      "group1 group2 meandiff p-adj   lower   upper  reject\n",
      "----------------------------------------------------\n",
      "     A      C    -20.0 0.0705 -42.6696 2.6696  False\n",
      "----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "tukey = pairwise_tukeyhsd(sales_data['Sales'], sales_data['Store'])\n",
    "print(tukey.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will output a table with the results of the post-hoc tests, including the difference between each pair of stores and whether the difference is significant or not."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
